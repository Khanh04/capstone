{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification,Trainer,TrainingArguments, logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import traceback\n",
        "import warnings"
      ],
      "metadata": {
        "id": "Wh0CWfE3r0ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount (\"/content/drive\")\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/TEST\")\n",
        "os.environ['WANDB_MODE'] = 'disabled'\n",
        "model_name=\"./MODEL/qa_model\"\n",
        "output_dir=\"./MODEL/qa_model2\"\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyuvVUN3qt5d",
        "outputId": "3728d248-036d-4bbc-c139-068cf7bb5138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp1 = pd.read_csv(\"qa_pairs.csv\")[[\"questions\", \"answers\", \"labels\"]] #1000 perfect + 100 good/bad eli5 + 100 bad gpt2 + 100 bad gpt2 finetune\n",
        "df_temp2 = pd.read_csv(\"qa_pairs2.csv\")[[\"questions\", \"answers\", \"labels\"]] #1200 eli5 finetune labeled by ROUGE_L\n",
        "df_temp2 = df_temp2[df_temp2[\"labels\"]==0]\n",
        "df_temp3 = pd.read_csv(\"qa_pairs3_simple.csv\")[[\"questions\", \"answers\", \"labels\"]] #247 eli5 from LLAMA ==> bart-large-cnn label by gpt-4o\n",
        "df_QA = pd.concat([df_temp1, df_temp2, df_temp3], axis=0, ignore_index=True).reset_index(drop=True)\n",
        "len(df_QA), len(df_QA[df_QA[\"labels\"]==1]), len(df_QA[df_QA[\"labels\"]==0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yiK8v7W1keI",
        "outputId": "e840a9df-b182-4fd8-81af-2487844f9cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2180, 1299, 881)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_qa_model(df_QA):\n",
        "    print(\"Preparing data...\")\n",
        "    questions = df_QA['questions'].astype(str).tolist()\n",
        "    answers = df_QA['answers'].astype(str).tolist()\n",
        "    labels = df_QA['labels'].astype(np.int64).tolist()\n",
        "    try:\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "        model = RobertaForSequenceClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=2,\n",
        "            problem_type=\"single_label_classification\",\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None, None\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"Model moved to GPU\")\n",
        "    try:\n",
        "        train_questions, val_questions, train_answers, val_answers, train_labels, val_labels = train_test_split(\n",
        "            questions, answers, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error splitting data: {e}\")\n",
        "        return None, None, None\n",
        "    class QADataset(Dataset):\n",
        "        def __init__(self, questions, answers, labels, tokenizer, max_length=512):\n",
        "            self.tokenizer = tokenizer\n",
        "            self.questions = questions\n",
        "            self.answers = answers\n",
        "            self.labels = labels\n",
        "            self.max_length = max_length\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "        def __getitem__(self, idx):\n",
        "            question = str(self.questions[idx])\n",
        "            answer = str(self.answers[idx])\n",
        "            text = f\"Question: {question} Answer: {answer}\"\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'labels': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "                'input_texts': text\n",
        "            }\n",
        "    class QAQualityLoss(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        def forward(self, outputs, targets, input_texts, attention_mask):\n",
        "            logits = outputs.logits\n",
        "            loss = F.cross_entropy(logits, targets, reduction='none')  # Get per-example loss\n",
        "            mask_weight = attention_mask.float().mean(dim=-1)\n",
        "            weighted_loss = (loss * mask_weight).mean()\n",
        "\n",
        "            # Get predictions for logging\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "            accuracy = (preds == targets).float().mean()\n",
        "\n",
        "            return weighted_loss, {\n",
        "                'loss': weighted_loss.item(),\n",
        "                'batch_accuracy': accuracy.item()\n",
        "            }\n",
        "    class WeightedTrainer(Trainer):\n",
        "        def __init__(self, quality_loss=None, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.quality_loss = quality_loss if quality_loss else QAQualityLoss()\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "            labels = inputs.pop(\"labels\")\n",
        "            outputs = model(**inputs)\n",
        "            loss, loss_components = self.quality_loss(\n",
        "                outputs,\n",
        "                labels,\n",
        "                inputs.get('input_texts', []),\n",
        "                inputs['attention_mask']\n",
        "            )\n",
        "            self.log(loss_components)\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "    def compute_metrics(pred):\n",
        "            labels = pred.label_ids\n",
        "            preds = pred.predictions.argmax(-1)\n",
        "            metrics = {\n",
        "                'eval_accuracy': accuracy_score(labels, preds),\n",
        "                'eval_precision': precision_score(labels, preds, average='weighted'),\n",
        "                'eval_recall': recall_score(labels, preds, average='weighted'),\n",
        "                'eval_f1': f1_score(labels, preds, average='weighted'),\n",
        "                'eval_confusion_matrix': confusion_matrix(labels, preds).tolist()\n",
        "            }\n",
        "            print(f\"Evaluation metrics: {metrics}\")\n",
        "            return metrics\n",
        "    train_dataset = QADataset(train_questions, train_answers, train_labels, tokenizer)\n",
        "    val_dataset = QADataset(val_questions, val_answers, val_labels, tokenizer)\n",
        "    quality_loss = QAQualityLoss()\n",
        "    if torch.cuda.is_available(): quality_loss = quality_loss.cuda()\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,\n",
        "      num_train_epochs=3,\n",
        "      per_device_train_batch_size=16,\n",
        "      per_device_eval_batch_size=16,\n",
        "      evaluation_strategy=\"steps\",\n",
        "      eval_steps=100,\n",
        "      save_strategy=\"steps\",\n",
        "      save_steps=100,\n",
        "      load_best_model_at_end=True,\n",
        "      metric_for_best_model=\"eval_accuracy\",\n",
        "      greater_is_better=True,\n",
        "      logging_steps=100,\n",
        "      report_to=\"tensorboard\",\n",
        "    )\n",
        "    trainer = WeightedTrainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      quality_loss=quality_loss,\n",
        "      compute_metrics=compute_metrics\n",
        "    )\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\"Training completed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        return None, None, None\n",
        "    return model, tokenizer, trainer"
      ],
      "metadata": {
        "id": "X6Fm5OzC5mmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer, trainer = train_qa_model(df_QA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "S0QKlNFUqrCH",
        "outputId": "8702a254-fb24-4c77-f3a6-c43562fbe634"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Model moved to GPU\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [301/327 01:53 < 00:09, 2.62 it/s, Epoch 2.75/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.008388</td>\n",
              "      <td>0.016856</td>\n",
              "      <td>0.974771</td>\n",
              "      <td>0.974795</td>\n",
              "      <td>0.974771</td>\n",
              "      <td>0.974735</td>\n",
              "      <td>[[169, 7], [4, 256]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>0.012591</td>\n",
              "      <td>0.979358</td>\n",
              "      <td>0.979527</td>\n",
              "      <td>0.979358</td>\n",
              "      <td>0.979307</td>\n",
              "      <td>[[169, 7], [2, 258]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.016491</td>\n",
              "      <td>0.977064</td>\n",
              "      <td>0.977889</td>\n",
              "      <td>0.977064</td>\n",
              "      <td>0.977140</td>\n",
              "      <td>[[175, 1], [9, 251]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"[[169, 7], [4, 256]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9747706422018348, 'eval_precision': 0.9747946874928797, 'eval_recall': 0.9747706422018348, 'eval_f1': 0.9747345661013931, 'eval_confusion_matrix': [[169, 7], [4, 256]]}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"[[169, 7], [2, 258]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9793577981651376, 'eval_precision': 0.9795265961915925, 'eval_recall': 0.9793577981651376, 'eval_f1': 0.9793073753309589, 'eval_confusion_matrix': [[169, 7], [2, 258]]}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"[[175, 1], [9, 251]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9770642201834863, 'eval_precision': 0.9778888952203671, 'eval_recall': 0.9770642201834863, 'eval_f1': 0.9771398764016309, 'eval_confusion_matrix': [[175, 1], [9, 251]]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [327/327 02:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.008388</td>\n",
              "      <td>0.016856</td>\n",
              "      <td>0.974771</td>\n",
              "      <td>0.974795</td>\n",
              "      <td>0.974771</td>\n",
              "      <td>0.974735</td>\n",
              "      <td>[[169, 7], [4, 256]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>0.012591</td>\n",
              "      <td>0.979358</td>\n",
              "      <td>0.979527</td>\n",
              "      <td>0.979358</td>\n",
              "      <td>0.979307</td>\n",
              "      <td>[[169, 7], [2, 258]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.016491</td>\n",
              "      <td>0.977064</td>\n",
              "      <td>0.977889</td>\n",
              "      <td>0.977064</td>\n",
              "      <td>0.977140</td>\n",
              "      <td>[[175, 1], [9, 251]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKKp7gLV73kK",
        "outputId": "9d6e8a9b-2d48-441b-b866-466498ca8457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./MODEL/qa_model2/tokenizer_config.json',\n",
              " './MODEL/qa_model2/special_tokens_map.json',\n",
              " './MODEL/qa_model2/vocab.json',\n",
              " './MODEL/qa_model2/merges.txt',\n",
              " './MODEL/qa_model2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}