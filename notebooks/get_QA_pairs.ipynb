{"cells":[{"cell_type":"code","source":["#### The code is from Irene Yi-Ju Su ####\n","from google.colab import drive\n","drive.mount (\"/content/drive/\")\n","import os\n","os.chdir (\"/content/drive/MyDrive/TEST\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dldhz2xsFM-O","executionInfo":{"status":"ok","timestamp":1733882856063,"user_tz":-480,"elapsed":128314,"user":{"displayName":"Yi-Ju Su","userId":"03011374787142444980"}},"outputId":"bfa18d4b-ee12-4e00-e001-6888b1b2a103"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","df_QA = pd.read_csv(\"QA_pairs.csv\")\n","output_max_length = 1024"],"metadata":{"id":"yDrwqOhekQak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","  if pd.isna(text): return \"\"\n","  if not isinstance(text, str): text = str(text)\n","  return re.sub(r'\\s+', \" \", text.lower().strip())\n","def df_prepare_dataset(df):\n","  df[\"Question\"], df[\"Dataset_Answer\"] = df[\"Question\"].apply(clean_text), df[\"Dataset_Answer\"].apply(clean_text)\n","  df = df[(df[\"Question\"] !=\"\") & (df[\"Dataset_Answer\"] !=\"\")]\n","  return df\n","def clean_generated(generated):\n","  temp = re.sub(r'[\\n|\\\\|\\x0f-\\x1f|\\x7f-\\xff]', \"\", generated)\n","  temp = re.sub(r'\\s+', \" \", temp).capitalize()\n","  temp = re.sub(r'\\.{4,}', '...', temp)\n","  temp = re.sub(r'\\.([a-zA-Z])', r'. \\1', temp)\n","  temp = re.sub(r'(?<=[\\.\\?\\!]\\s)(\\w)|^(\\w)', lambda m: m.group().upper(), temp)\n","  return temp"],"metadata":{"id":"hKP2nXluoYm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_answer(question, model):\n","    device = next(model.parameters()).device\n","    input = tokenizer(\n","        f\"question: {clean_text(question)} answer: \", #prompt\n","        return_tensors=\"pt\",  #no need to pad. If pad make additional pairs, which result in worse result, waste memory, waste time\n","    ).to(device)\n","    output = model.generate(\n","        **input,\n","        do_sample = True, temperature = 0.7, top_p = 0.9,\n","        max_length = output_max_length, num_return_sequences = 1, no_repeat_ngram_size = 2, #no need to pad. Let model stop natually or at max_length\n","    )\n","    generated = tokenizer.decode(output[0], skip_special_tokens=True).split(\"answer:\")[-1].strip() #only get text after \"question: [question body] answer:\"\n","    return clean_generated(generated)"],"metadata":{"id":"YNcXVDdvnTZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, GPT2TokenizerFast\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","Baseline_GPT2=[]\n","for i in range(100):\n","    Baseline_GPT2.append(get_answer(df_QA.iloc[i][\"Question\"], model))\n","df_QA[\"GPT2_Answer\"]=Baseline_GPT2"],"metadata":{"id":"MSssTgXIfQfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/TEST/MODEL/train_gpt2\")\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"/content/drive/MyDrive/TEST/MODEL/train_gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","Finetuned_GPT2=[]\n","for i in range(100):\n","    Finetuned_GPT2.append(get_answer(df_QA.iloc[i][\"Question\"], model))\n","df_QA[\"GPT2_Finetuned\"]=Finetuned_GPT2"],"metadata":{"id":"fXD18ayPfU96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_QA.to_csv(\"QA_pairs.csv\",index = False)"],"metadata":{"id":"Ua_d7gehfaS7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1F22yWWwgzHamZUoRVSGA_yhvAuo1W7De","timestamp":1733314229368},{"file_id":"12gZsBu5vc6kx2vg-rATVGDGSC4vyGlD4","timestamp":1733130551447},{"file_id":"1oxos2UzotWd_BI-GTEO2zLg_v8uL8fca","timestamp":1733060891713},{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1732355256687}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}