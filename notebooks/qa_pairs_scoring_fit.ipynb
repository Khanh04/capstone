{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification,Trainer,TrainingArguments, logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import traceback\n",
        "import warnings"
      ],
      "metadata": {
        "id": "Wh0CWfE3r0ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount (\"/content/drive\")\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/TEST\")\n",
        "os.environ['WANDB_MODE'] = 'disabled'\n",
        "model_name=\"./MODEL/qa_model\"\n",
        "output_dir=\"./MODEL/qa_model2\"\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyuvVUN3qt5d",
        "outputId": "794ccb74-8d8d-4ad6-9350-b62c02c479c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp1 = pd.read_csv(\"qa_pairs.csv\")[[\"questions\", \"answers\", \"labels\"]] #1000 perfect + 100 good/bad eli5 + 100 bad gpt2 + 100 bad gpt2 finetune\n",
        "df_temp2 = pd.read_csv(\"qa_pairs2.csv\")[[\"questions\", \"answers\", \"labels\"]] #1200 eli5 finetune labeled by ROUGE_L\n",
        "df_temp3 = pd.read_csv(\"qa_pairs3_simple.csv\")[[\"questions\", \"answers\", \"labels\"]] #247 eli5 from LLAMA ==> bart-large-cnn label by gpt-4o\n",
        "df_QA = pd.concat([df_temp1, df_temp2, df_temp3], axis=0, ignore_index=True).reset_index(drop=True)\n",
        "len(df_QA), len(df_QA[df_QA[\"labels\"]==1]), len(df_QA[df_QA[\"labels\"]==0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yiK8v7W1keI",
        "outputId": "f97294ab-a177-4435-e004-e1d73ef6711d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2747, 1866, 881)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_qa_model(df_QA):\n",
        "    print(\"Preparing data...\")\n",
        "    questions = df_QA['questions'].astype(str).tolist()\n",
        "    answers = df_QA['answers'].astype(str).tolist()\n",
        "    labels = df_QA['labels'].astype(np.int64).tolist()\n",
        "    try:\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "        model = RobertaForSequenceClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=2,\n",
        "            problem_type=\"single_label_classification\",\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None, None\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"Model moved to GPU\")\n",
        "    try:\n",
        "        train_questions, val_questions, train_answers, val_answers, train_labels, val_labels = train_test_split(\n",
        "            questions, answers, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error splitting data: {e}\")\n",
        "        return None, None, None\n",
        "    class QADataset(Dataset):\n",
        "        def __init__(self, questions, answers, labels, tokenizer, max_length=512):\n",
        "            self.tokenizer = tokenizer\n",
        "            self.questions = questions\n",
        "            self.answers = answers\n",
        "            self.labels = labels\n",
        "            self.max_length = max_length\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "        def __getitem__(self, idx):\n",
        "            question = str(self.questions[idx])\n",
        "            answer = str(self.answers[idx])\n",
        "            text = f\"Question: {question} Answer: {answer}\"\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'labels': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "                'input_texts': text\n",
        "            }\n",
        "    class QAQualityLoss(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        def forward(self, outputs, targets, input_texts, attention_mask):\n",
        "            logits = outputs.logits\n",
        "            loss = F.cross_entropy(logits, targets, reduction='none')  # Get per-example loss\n",
        "            mask_weight = attention_mask.float().mean(dim=-1)\n",
        "            weighted_loss = (loss * mask_weight).mean()\n",
        "\n",
        "            # Get predictions for logging\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "            accuracy = (preds == targets).float().mean()\n",
        "\n",
        "            return weighted_loss, {\n",
        "                'loss': weighted_loss.item(),\n",
        "                'batch_accuracy': accuracy.item()\n",
        "            }\n",
        "    class WeightedTrainer(Trainer):\n",
        "        def __init__(self, quality_loss=None, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.quality_loss = quality_loss if quality_loss else QAQualityLoss()\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "            labels = inputs.pop(\"labels\")\n",
        "            outputs = model(**inputs)\n",
        "            loss, loss_components = self.quality_loss(\n",
        "                outputs,\n",
        "                labels,\n",
        "                inputs.get('input_texts', []),\n",
        "                inputs['attention_mask']\n",
        "            )\n",
        "            self.log(loss_components)\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "    def compute_metrics(pred):\n",
        "            labels = pred.label_ids\n",
        "            preds = pred.predictions.argmax(-1)\n",
        "            metrics = {\n",
        "                'eval_accuracy': accuracy_score(labels, preds),\n",
        "                'eval_precision': precision_score(labels, preds, average='weighted'),\n",
        "                'eval_recall': recall_score(labels, preds, average='weighted'),\n",
        "                'eval_f1': f1_score(labels, preds, average='weighted'),\n",
        "                'eval_confusion_matrix': confusion_matrix(labels, preds).tolist()\n",
        "            }\n",
        "            print(f\"Evaluation metrics: {metrics}\")\n",
        "            return metrics\n",
        "    train_dataset = QADataset(train_questions, train_answers, train_labels, tokenizer)\n",
        "    val_dataset = QADataset(val_questions, val_answers, val_labels, tokenizer)\n",
        "    quality_loss = QAQualityLoss()\n",
        "    if torch.cuda.is_available(): quality_loss = quality_loss.cuda()\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,\n",
        "      num_train_epochs=3,\n",
        "      per_device_train_batch_size=16,\n",
        "      per_device_eval_batch_size=16,\n",
        "      evaluation_strategy=\"steps\",\n",
        "      eval_steps=100,\n",
        "      save_strategy=\"steps\",\n",
        "      save_steps=100,\n",
        "      load_best_model_at_end=True,\n",
        "      metric_for_best_model=\"eval_accuracy\",\n",
        "      greater_is_better=True,\n",
        "      logging_steps=100,\n",
        "      report_to=\"tensorboard\",\n",
        "    )\n",
        "    trainer = WeightedTrainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      quality_loss=quality_loss,\n",
        "      compute_metrics=compute_metrics\n",
        "    )\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\"Training completed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        return None, None, None\n",
        "    return model, tokenizer, trainer"
      ],
      "metadata": {
        "id": "X6Fm5OzC5mmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer, trainer = train_qa_model(df_QA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "S0QKlNFUqrCH",
        "outputId": "5d2f0c13-6c64-407f-a8fe-ed554642d49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Model moved to GPU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='414' max='414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [414/414 02:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.003235</td>\n",
              "      <td>0.045376</td>\n",
              "      <td>0.934545</td>\n",
              "      <td>0.936144</td>\n",
              "      <td>0.934545</td>\n",
              "      <td>0.935006</td>\n",
              "      <td>[[163, 13], [23, 351]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.112755</td>\n",
              "      <td>0.053411</td>\n",
              "      <td>0.947273</td>\n",
              "      <td>0.948282</td>\n",
              "      <td>0.947273</td>\n",
              "      <td>0.946422</td>\n",
              "      <td>[[152, 24], [5, 369]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.044991</td>\n",
              "      <td>0.947273</td>\n",
              "      <td>0.948143</td>\n",
              "      <td>0.947273</td>\n",
              "      <td>0.947538</td>\n",
              "      <td>[[165, 11], [18, 356]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>0.048626</td>\n",
              "      <td>0.941818</td>\n",
              "      <td>0.942270</td>\n",
              "      <td>0.941818</td>\n",
              "      <td>0.941989</td>\n",
              "      <td>[[162, 14], [18, 356]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[163, 13], [23, 351]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9345454545454546, 'eval_precision': 0.9361443932411674, 'eval_recall': 0.9345454545454546, 'eval_f1': 0.9350060638727934, 'eval_confusion_matrix': [[163, 13], [23, 351]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[152, 24], [5, 369]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9472727272727273, 'eval_precision': 0.9482821996402003, 'eval_recall': 0.9472727272727273, 'eval_f1': 0.9464215715063173, 'eval_confusion_matrix': [[152, 24], [5, 369]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[165, 11], [18, 356]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9472727272727273, 'eval_precision': 0.9481431187742886, 'eval_recall': 0.9472727272727273, 'eval_f1': 0.9475377322672441, 'eval_confusion_matrix': [[165, 11], [18, 356]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[[162, 14], [18, 356]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_accuracy': 0.9418181818181818, 'eval_precision': 0.9422702702702703, 'eval_recall': 0.9418181818181818, 'eval_f1': 0.941988643228223, 'eval_confusion_matrix': [[162, 14], [18, 356]]}\n",
            "Training completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKKp7gLV73kK",
        "outputId": "6474624b-9abb-43fa-bb0c-846a9884eb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./MODEL/qa_model2/tokenizer_config.json',\n",
              " './MODEL/qa_model2/special_tokens_map.json',\n",
              " './MODEL/qa_model2/vocab.json',\n",
              " './MODEL/qa_model2/merges.txt',\n",
              " './MODEL/qa_model2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}